---
title: "HR Analytics: Prediction of Candidates Who Accept or Reject the Company Offer and the City Development Index"
author: "Team 3: Xinping Yu, Ruchika Venkateswaran, Yigit Demiralp, Bosoo Kim, Muyan Xie"
date: "3/1/2021"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# BA810 Team Project

## Introduction and Motivation
The dataset chosen by our group will be used in the field of "Human Resource Analytics".Our primary goal is to utilize the dataset to predict whether a candidate training for a data science position will accept or reject a full time offer from the company. The dataset has been compiled by a data-related company that is aiming to reduce the time and cost spent by the human resources division to rain candidates who are potential full time employees. In addition, we will also discuss how these factors impact a candidate's decision to accept the offer and which is the most significant factor. We will also be using the most important features to predict the city development index. Generally, cities that are more developed provide a fertile ground for the development of science, technology, culture, and innovation. The prediction of the city development index can provide HR teams with deeper insight on whether they should train candidates who belong to cities with higher or lower development indexes. 

## Impact of the Predictions
Enhanced candidate experience

- Better match of job seekers to roles
- More informative pre-hire communication

Efficient and effective recruitment

- Better prioritization of job requisitions
- Accelerated time-to-hire
- Identification of the most qualified candidates
- Minimizing the impact of employee turnover

## Description of the Dataset
Our dataset has 19,158 observations and 14 features and approximately 8% of the dataset consists of missing values. The features of our dataset have been listed below

- enrollee_id : Unique ID for candidate
- city: City code
- city_ development _index : Development index of the city (scaled)
- gender: Gender
- relevent_experience: Relevant experience of candidate
- enrolled_university: Type of University course enrolled if any
- education_level: Education level of candidate
- major_discipline :Education major discipline of candidate
- experience: Candidate total experience in years
- company_size: No of employees in current employer's company
- company_type : Type of current employer
- Last new job: Difference in years between previous job and current job
- training_hours: training hours completed
- target: 0 - Not looking for job change, 1 - Looking for a job change

*** 

## Loading the Data
```{r}
## Uploading data

library(groupdata2)
library(data.table)
library(ggplot2)
library(ggthemes)
library(scales)
library(glmnet)
library(tidyr)
library(dplyr)
library(tidyverse)
library(caret)
library(corrplot)
library(RColorBrewer)
library(leaps)
library(MASS)
library(xgboost)
library(readr)
library(stringr)
library(car)
library(gbm)
library(rpart)
library(rpart.plot)
library(ggridges)
library(viridis)
library(hrbrthemes)
library(ggridges)
library(forcats)
library(randomForest)
library(randomForestExplainer)
theme_set(theme_bw())
```

```{r}
df <- fread("C:/Users/ruchi/OneDrive/Documents/Ruchika/Boston University/BA810/Team Project/aug_train.csv")
df <- as.data.table(df)
```


```{r}
#viewing the head of dataset
head(df)

#structure of the dataset
str(df)

#summary to view data types and missing values 
summary(df)
```

*** 

## Data Cleaning

```{r}
#assigning missing values of 'last_new_job' to 0 
#updating observations with 'never' to 0
levels(df$last_new_job) <- c(levels(df$last_new_job), 0) 
df$last_new_job[df$last_new_job  == 'never']  <- 0 
df$last_new_job[df$last_new_job == ""]<-0
table(df$last_new_job)
```

```{r}
## Drop "Primary School" under column - education_level
df <-df[!(education_level) %like% "Primary School"]
```

```{r}
#Drop missing values for each column
df[df$enrollee_id == ''] = NA
df[df$city == ''] = NA
df[df$enrolled_university == ''] = NA
df[df$city_development_index == ''] = NA
df[df$gender == ''] = NA
df[df$relevent_experience == ''] = NA
df[df$education_level == ''] = NA
df[df$major_discipline == ''] = NA 
df[df$experience == ''] = NA
df[df$company_size == ''] = NA
df[df$company_type == ''] = NA
df[df$last_new_job == ''] = NA
df[df$training_hours == ''] = NA
df[df$target == ''] = NA
```

```{r}
#Experience for more than 4 becomes 5, never becomes 0
levels(df$last_new_job) <- c(levels(df$last_new_job), '5') 
df$last_new_job[df$last_new_job == '>4'] <- '5'
unique(df$last_new_job)
#levels(df$last_new_job) <- c(levels(df$last_new_job), '0') 
df$last_new_job[df$last_new_job == 'never'] <- '0'
```

```{r}
#Change column to numeric
df$last_new_job <- as.numeric(as.character(df$last_new_job))
```

```{r}
#Company size for less than 10 becomes 0-9,
levels(df$company_size) <- c(levels(df$company_size), '0-9')
df$company_size[df$company_size == '<10'] <- '0-9'
```

```{r}
#Changing 'graduate' to 'undergraduate' since we already have data for Masters candidates 
df$education_level[df$education_level == 'Graduate'] <- 'Undergraduate'
```


```{r}
df$education_level = factor(df$education_level, levels=c('Undergraduate', 'Masters', 'Phd'))
```

```{r}
#Experience for more than 20 becomes 21                                        
levels(df$experience) <- c(levels(df$experience), '21')
df$experience[df$experience == '>20'] <- '21'
unique(df$experience)
```

```{r}
#Experience for less than 1 becomes 0
levels(df$experience) <- c(levels(df$experience), '0')
df$experience[df$experience == '<1'] <- '0'
```

```{r}
#Change column to numeric
df$experience <- as.numeric(as.character(df$experience))
```

```{r}
#replace missing values in enrolled university with 'no enrollment'
df[is.na(enrolled_university), enrolled_university := 'no_enrollment']
```

```{r}
#confirming that there are 0 observations with null values in enrolled_university
sum(is.na(df$enrolled_university))
```

```{r}
#confirming there are no missing values for education_level and major_discipline
df[!(is.na(df$education_level)) & !(is.na(df$major_discipline))]
```

```{r}
# Company-size:
# 1) Impute missing values to mode ("50-99" has the highest frequency)
a <- table(df$company_size)   
# count the values
a
df$company_size[is.na(df$company_size)] <- '50-99'
```

```{r}
#confirming that there are no missing values in company size 
unique(df$company_size)  
```

```{r}
# 2) change '10/49' to '10-49'
levels(df$company_size) <- c(levels(df$company_size), '10-49') 
df$company_size[df$company_size == '10/49'] <- '10-49'
unique(df$company_size)  
```

```{r}
# 4) Company-type: drop missing values
df <- na.omit(df)
sum(is.na(df))
str(df)
```

```{r}
# drop column city and enrollee_id  
 df <- subset(df, select = -c(enrollee_id,city))
```

### Summary of Data Cleaning
We identified missing values and also removed variables which have no predictive power. A summary of the data cleaning process has been provided below:

#### Last New Job
Under "last_new_job", each candidate belongs to a scale ranging from "0" to "4" or "never". Observations belonging to the 'never' category indicate that these candidates do not have previous work experience. For this reason,  we have updated observations with "never" to 0. We have also assigned the missing values of "last_new_job" to 0. There is an additional category ">4" under this feature. We have assigned candidates with experience for '>4' as 5, and those who 'never have experience' have been assigned 0.

#### Education Level
We noticed that some candidates only have "primary school" education experience. Since most companies require candidates of at least 18 years of age, we have removed observations with candidates educated only upto primary school levels. 

#### Company Size And Experience 
We changed the value of "<10" to "0-9", and "10/49" to "10-49" to provide a more meaningful understanding of the categories. We also replaced NA values under "company_size" with the mode ("50-99") since it has the highest frequency. We also changed the value under the feature "experience" from ">20" to "21", "<1" to "0". We then proceed to convert the "experience" feature to a numeric variable that can easily be used in our models.

#### University Enrollments 
Before dropping NA values, we change NA values under "enrolled_university" to "no enrollment". 

#### Dropping Null Values
After cleaning and imputing missing values, our final step was to drop the remaining NA values under the features "company_size", "enrolled_id", "city", "education_level", and "major_discipline".

*** 

## Exploratory Data Analysis

### Training Hours

The distribution below displays that the training hours is skewed to the right, with the mean number of training hours approximately around 60 hours. 

```{r}
#plotting the distribution of training hours with the dotted line that marks the mean
ggplot(df, aes(x=training_hours)) +
  geom_histogram(binwidth=.5, colour="black", fill="white") +
  geom_vline(aes(xintercept=mean(training_hours, na.rm=T)),   # Ignore NA values for mean
             color="red", linetype="dashed", size=1) + ggtitle('Distribution of Training Hours') + ylab('Number of Candidates') + xlab('Training Hours')
```

### City Development Index

The charts below displays that candidates looking for job change belong to cities with lower development indexes. Candidates who belong to more developed cities are more likely to reject the job offer.

```{r}
#discuss city development index, No change job(0,blue) vs will change job(1,black)
ggplot(data = df, mapping = aes(x = city_development_index)) +
  geom_freqpoly(mapping = aes(group = target,color = target), binwidth = .01)+
  ggtitle("Number of candidates with different targets by city development index") +
  ylab("Number of candidates") +
  xlab("City development index")
```

 
```{r}
   ggplot(df, aes(y=company_type, x=city_development_index,  fill=company_type)) +
     geom_density_ridges(alpha=0.4, stat='binline', bins=20) +
     theme_ridges() +
     theme(
       legend.position='none',
       panel.spacing = unit(0.3, 'lines'),
       strip.text.x = element_text(size = 8)
     ) +
     labs(title = 'Company type based on City index') +
     xlab('') +
     ylab('Company type')
```
  
```{r}
##city development index
ggplot(df, aes(city_development_index, fill = as.factor(target)))+
  geom_density(alpha = 0.5)+ ggtitle('Density Plot for City Development Index by Candidates who Accept/Reject the Offer') + ylab('Density') + xlab('City Development Index')
```

### Education, Discpline Major and University Enrollments

The dataset consists of more number of students with graduate degrees, as compared to Masters and PhD degrees.Majority of the candidates have a STEM education background. The violin plot below displays that the range in the number of training hours is highest among STEM students, but generally similar ranges can be observed across all disciplines.Interestingly, candidates without any major have a smaller range in the number of training hours. 
```{r}
# count how many people in different education level where target equal to 1
phd <- df[df$education_level == 'Phd' & df$target == 1, .N ]
mas <- df[df$education_level == 'Masters' & df$target == 1, .N]
gra <- df[df$education_level == 'Undergraduate' & df$target == 1, .N]
# the percentage of people in different education level where target equal to 1
all_target <- df[df$target == 1, .N]
phd_p <- phd/all_target
mas_p <- mas/all_target
gra_p <- gra/all_target

# plot for education_level
ggplot(data = df) +
  geom_bar(mapping = aes(x = education_level), fill="tomato3") + ggtitle("Number of candidates by education level") + ylab("Number of candidates") + xlab("Type of education level")
```
```{r}
# count how many people in different major where target equal to 1
stem <- df[df$major_discipline == 'STEM' & df$target == 1, .N ]
hum <- df[df$major_discipline == 'Humanities' & df$target == 1, .N]
other <- df[df$major_discipline == 'Other' & df$target == 1, .N]
bus <- df[df$major_discipline == 'Business Degree' & df$target == 1, .N]
art <- df[df$major_discipline == 'Arts' & df$target == 1, .N]
# the percentage of people in different major where target equal to 1
stem_p <- stem/all_target
hum_p <- hum/all_target
other_p <- other/all_target
hum_p <- hum/all_target
art_p <- art/all_target
# plot of major discipline
ggplot(df, aes(df$major_discipline)) +
  geom_bar(fill="tomato3") + ggtitle("Number of candidates by discipline") + ylab("Number of candidates") + xlab("Type of major")
```
```{r}
# University Enrollments by Training Hours
ggplot(df, aes(x=enrolled_university, y=training_hours)) +
  geom_bar(stat="identity", width=.5, fill="tomato3") +
  labs(title="University Enrollments by Training Hours") +
  theme(axis.text.x = element_text(angle=65, vjust=0.6)) + xlab('University Enrollment') + ylab('Training Hours')
```
```{r}
#Plot
g <- ggplot(df, aes(major_discipline, training_hours))
g + geom_violin(fill="tomato3") +
  labs(title="Number of training hours by discipline",
       x="Major",
       y="Training hours") +
  theme(axis.text.x = element_text(angle = 90, vjust=0.5),
        panel.grid.minor = element_blank())
```

```{r}
#defining new df 'hp' for plotting
hp <- ggplot(df, aes(x=experience)) + geom_histogram(binwidth=2,colour="white", fill="tomato3")
hp + facet_grid(gender ~ education_level, scales="free") + ggtitle('Experience by Gender and Graduate Level') + ylab('Number of Candidates') + xlab('Experience')
hp + facet_grid(education_level ~ enrolled_university, scales="free")+ ggtitle('Experience by University and Education Level') + ylab('Number of Candidates') + xlab('Experience')
```

```{r}
#examining outliers 
ggplot(df, aes(x=relevent_experience, y=last_new_job, fill=education_level)) + geom_boxplot()+ ggtitle('Distribution of Last New Job by Experience and University Enrollment') + ylab('Last New Job') + xlab('Relevant Experience')
```


### Work Experience, Company Type and Gender
The dataset has more number of males and this could be attributed to the fact that the company has not yet collected much data on candidates belonging to other genders.The dataset also consists of more number of candidates belonging to private companies with the size ranging from 50-99 employees. Interestingly, some candidates across across all genders have received training upto 300 hours. 
```{r}
# gender count
ggplot(data = df) +
  stat_count(mapping = aes(x = gender), fill="tomato3")+ ggtitle('Number of Candidates by gender') + ylab('Number of Candidates') + xlab('Gender')
```

```{r}
#gender count by company type
ggplot(data = df) + geom_bar(mapping = aes(x = company_type, fill = gender)) + ggtitle('Number of Candidates in Each Company Type by Gender') + ylab('Number of Candidates') + xlab('Company Type')
```
```{r}
df %>% 
  group_by(company_size) %>% 
  count(target) %>% 
  ggplot(aes(reorder(company_size, n), n, fill = target))+
  geom_col()+
  coord_flip() + ggtitle('Number of Candidates Who Accept or Reject Job Offers based on Company Size') + ylab('Company Size') + xlab('Number of Candidates')

``` 


```{r}
#examining outliers 
ggplot(df, aes(x=gender, y=training_hours, fill=gender)) + geom_boxplot()+ ggtitle('Distribution of Training Hours by Gender') + ylab('Training Hours') + xlab('Gender')
```

```{r}
# min, max and median training hours
ggplot(data = df) +
  stat_summary(
    mapping = aes(x = company_type, y = training_hours),
    fun.min = min,
    fun.max = max,
    fun = median
  )+ ggtitle('Summary Statistics by Company Type') + ylab('Training Hours') + xlab('Company Type')
```

```{r}
#experience regarding target
ggplot(data = df) +
  geom_count(mapping = aes(x = target, y = experience))+
  ggtitle("Candidates distribution by experience") +
  ylab("Experience") +
  xlab("No change job vs will change job")
```



```{r}
# density plot for training hours by gender
ggplot(df, aes(x=training_hours, fill=gender)) + geom_density(alpha=.3)+ ggtitle('Density Plot for Training Hours by Gender') + ylab('Number of Candidates') + xlab('Training Hours')
```



```{r}
#examining outliers 
ggplot(df, aes(x=gender, y=training_hours, fill=gender)) + geom_boxplot() + ggtitle('Distribution of Training Hours by Gender') + ylab('Training Hours') + xlab('Gender')
```
*** 

## Machine Learning (Model Building)

## Classification Models to Predict Whether Candidates Will Accept or Reject the Offer 
```{r}
# Drop dummy variable
dmy <- dummyVars(" ~ .", data = df, fullRank = T)
new_df <- data.frame(predict(dmy, newdata = df))
```

```{r}
#splitting the data into test and train data
new_df$target = as.factor(new_df$target)
# Determine row to split on: split
split <- round(nrow(new_df) * 0.80)

# Create train
train_df <- new_df[1:split, ]

# Create test
test_df <- new_df[(split + 1):nrow(new_df), ]
```

### Decision Tree 
```{r}
# creating the train control function for cross validation creating 5 folds. The same 5 folds will be used for all classification models 
train_control <- trainControl(method = "cv",
                              number = 5)
model_dt <- train(target ~., data = train_df,
               method = "rpart",
               trControl = train_control)
print(model_dt)
varImp(model_dt)
```

```{r}
# fit the model with test data and evaluate
class_pred <- predict(object = model_dt, newdata = test_df)
confusionMatrix(data = class_pred,reference = test_df$target, positive = "1")
```


### Random Forest 
```{r}
# build random forest
# apply 5-folds cross validation 

model_rf <- randomForest(target ~., data = train_df,  
               method = "rf", 
               trControl = train_control,
               localImp = TRUE) 
print(model_rf)
varImp(model_rf)

```

```{r}
# fit the model with test data and evaluate
class_pred <- predict(object = model_rf, newdata = test_df)
confusionMatrix(data = class_pred,reference = test_df$target, positive = "1")
```


```{r}
plot(model_rf)
```

```{r}
varImpPlot(model_rf,
           sort = T,
           n.var = 5,
           main = "Top 5 - Variable Importance")
```
Based on the variable importance plot of our random forest model, we can observe that city development index, experience, and last new job are the most important features in predicting if a candidate will accept the job offer. 

```{r}
importance_frame <- measure_importance(model_rf)
plot_multi_way_importance(importance_frame, size_measure = "no_of_nodes")
```

### Decision Tree Using Rpart
```{r}
model_rpart <- rpart(target ~., train_df,  control = rpart.control(cp = .0025))
```

```{r}
par(xpd = TRUE)
plot(model_rpart, compress=TRUE)
text(model_rpart, use.n=TRUE)

```

```{r}

rpart.plot(model_rpart, type = 1)
```

We can see from this overly simplified decision tree above that city development index, experience, and training hours are the top 3 variables that are important in predicting if a candidate will accept the job offer.

### Gradient Boost Model
```{r}
fit.btree <- gbm(target ~.,
data = train_df,
n.trees = 100,
distribution = 'multinomial',
cv.folds = 5,
interaction.depth = 2,
shrinkage = 0.001)

pred_gbm <- predict.gbm(fit.btree, test_df, n.trees = 100, type = 'response')
```

```{r}
relative.influence(fit.btree)
```

The gradient boost model also identifies city development index as the top feature in predicting whether a candidate will accept or reject the job offer. Additional features that are important no university enrollment, experience, training hours, and last new job are most important.


```{r}
gbm_labels = colnames(pred_gbm)[apply(pred_gbm, 1, which.max)]
```

```{r}
confMat <- table(test_df$target,gbm_labels)
confMat
```

```{r}
cm = confusionMatrix(test_df$target, as.factor(gbm_labels), positive = "1")
print(cm)

```

### Logistic Regression 
```{r}
model_dt <- train(target ~., data = train_df,
               method = "glm",
               trControl = train_control,
               family=binomial(link=logit))
print(model_dt)
varImp(model_dt)
```
We also ran a logistic regression to identify most important features. Apart from city development index, experience, last new job and training hours, additional features identified as important predictors include company size (10,000, 10-49 and 1000-4999), candidates who enrolled in part time courses and those who did not enroll in university. Interestingly, Masters level and undergraduate level students have not been listed above and only the feature on PhD level candidates has been listed as an important feature. 


```{r}
logistic_labels <- predict(model_dt, test_df)
cm = confusionMatrix(test_df$target, as.factor(logistic_labels), positive = "1")
print(cm)
```


## Regression Models to Predict City Development Index 
For our regression model, we are only using experience, no university enrollments, last new job and STEM discipline variables to predict the city development index. This can be attributed to the variable importance results in our classification models that display these 4 features as the most important features across all classification models above. 
```{r}
keeps <- c("city_development_index", "experience","enrolled_universityno_enrollment","last_new_job","major_disciplineSTEM")
new_df_th <- new_df[keeps]

# new_df_th <- scale(new_df_th)
# new_df_th <- as.data.frame(new_df_th)

split <- round(nrow(new_df_th) * 0.80)

# Create train and test data for regression models
train_df_th <- new_df_th[1:split, ]
test_df_th <- new_df_th[(split + 1):nrow(new_df_th), ]
```


## Linear Regression
```{r}
lmTemp = lm(city_development_index ~ ., data = train_df_th) 
#Create a linear regression with a quadratic coefficient
summary(lmTemp)

pred_train_lm <- predict(lmTemp, newdata = train_df_th)
mse_train.lm <- mean((pred_train_lm - train_df_th$city_development_index) ^ 2)
mse_train.lm

pred_lm <- predict(lmTemp, newdata = test_df_th)
mse_test.lm <- mean((pred_lm - test_df_th$city_development_index) ^ 2)
mse_test.lm
```

## Ridge Regression
```{r}
#set seed for reproducibality
set.seed(1)

# creating the train control function for cross validation creating 5 folds. The same 5 folds will be used for Ridge and Lasso regression
train_control <- trainControl(method = "cv",
                              number = 5)
model_ridge <- train(city_development_index ~., data = train_df_th,  
               method = "ridge", 
               trControl = train_control) 
  
# printing model performance metrics 
# along with other details 
print(model_ridge)
varImp(model_ridge)

pred_ridge <- predict(model_ridge, newdata = test_df_th)

pred_train_ridge <- predict(model_ridge, newdata = train_df_th)
mse_train.ridge <- mean((pred_train_ridge - train_df_th$city_development_index) ^ 2)
print('Train')
mse_train.ridge

pred_ridge <- predict(model_ridge, newdata = test_df_th)
mse_test.ridge <- mean((pred_ridge - test_df_th$city_development_index) ^ 2)
print('Test')
mse_test.ridge
```

## Lasso Regression
```{r}
#set seed for reproducibality
set.seed(1)

model_lasso <- train(city_development_index ~., data = train_df_th,  
               method = "lasso", 
               trControl = train_control) 
print(model_lasso)
varImp(model_lasso)

pred_lasso <- predict(model_lasso, newdata = test_df_th)

pred_train_lasso <- predict(model_lasso, newdata = train_df_th)
mse_train.lasso <- mean((pred_train_lasso - train_df_th$city_development_index) ^ 2)
print('Train')
mse_train.lasso

pred_lasso <- predict(model_lasso, newdata = test_df_th)
mse_test.lasso <- mean((pred_lasso - test_df_th$city_development_index) ^ 2)
print('Test')
mse_test.lasso
```

To find out the meaningful information and build a better model, we applied cross validation and also used a varImp function to identify which variables have the most influence on the city development index.

#### Variable Importance: 
The experience variable showed a score of 100, which means that this variable is extremely important or similar with our target "city development index". Other three variables, last new job, enrolled university, major discipline STEM showed scores below 15, indicating that it is not as statistically significantly as experience in predicting the city development index.

#### MSE: 
Both train and test MSE showed similar values for all linear, lasso, and ridge models, which means our model is very optimized with no evidence of overfitting or under fitting. We were also able to calculate very small values of MSEs. Here are training and test MSE values for all three regression models:
* Linear: 0.01177169 / 0.01170526
* Lasso: 0.01178403 / 0.01170773
* Ridge: 0.01177169 / 0.01170527

#### Lambda & R-square: 
The values of lambda and R-squares are very small (lambda is close to zero) for Ridge regression. Since the value is very small, we can conclude that the coefficients are not shrunk to a great extent and since R square is very small, we can conclude that all 4 features are important in predicting the city development index.The value of lambda in Lasso Regression that produces the lowest RMSE is 0.9. This value is higher than that of Ridge regression and only selects a subset of predictors (experience, last new job and no university enrollment) as predictors of city development index. However, we would have to re-engineer our features/conduct more research on identifying other features such as GDP, population, income levels, etc in order to improve the fit of our model (increase R square): 
* Linear: R^2 (0.1304)
* Lasso: Lambda (0e+00), R^2(0.1299193)
* Ridge: Lambda (0.1), R^2(0.1102777)

*** 

## Conclusion

### Chosen Model for Predicting Whether Candidates Will Accept or Reject the Offer (Classification)
The criteria for us to make the choice of the model depends on multiple aspects of the result. In the evaluation process, we considered not only the accuracy, but also the sensitivity, specificity, and balanced accuracy. Finally, we picked the Gradient boosting model as it is the best model with highest accuracy. All the models we have run including decision tree, random forest, and Gradient boost have close accuracy (all around 86 percent). We next try to compare the sensitivity and specificity and find that the Gradient boosting model has better sensitivity as compared to the remaining 3 models. Our test dataset has 1795 observations, with a 90% accuracy of prediction of the target value 0, i.e. prediction of candidates not looking for any job change. The Gradient boosting model shows its advantage on sensitivity (57 percent) which means it has fewer false negative predictions. It has predicted more correct values of candidates looking for job change (158 over 275) as compared to other models and therefore, we have picked the Gradient boost model.

The variable importance and tree plots display that city development index is the most important feature across all models in predicting whether candidates will accept or reject the job, followed by years of experience. This implies that companies should also consider the city development index when predicting whether candidates will accept or reject the offer. In our exploratory data analysis, we noticed that candidates belonging to more developed cities tend to reject job offers. Therefore, we find that it would be relevant to also use the most important variables to predict the city development index, which would help companies in guaging how much to invest in their employees. A higher development index and higher levels of work experience indicates that candidates will tend to reject the offer. This also helps companies to make the prediction for the cost of human force in the future.

### Chosen Model for Predicting the City Development Index (Regression)
After we run three classification models, we find out that "city_development_index" has the highest impact on our target variable. Which means that a candidate with a high "city_development_index" value would be more likely to reject the offer.

We pick the best model on three values which are MSE/RMSE, MAE, and R^2. After fitting test data into Lasso, Ridge and Linear regression models, we pick linear regression as the best model. Linear regression gives us MSE with 0.01170526 which is the lowest and small MSE indicates a better model on unseen data. The residual standard error is 0.1085 and the R^2 is 0.1304 which is the highest. R^2 was based on correlation between actual and predicted value, as the value near 1 which indicates a better model. Also, MSE for both train and test are very close for Linear regression which means there is no overfitting or under fitting. Therefore, our best model for regression would be linear regression. For this reason, we would recommend using a Linear Regression model, but also conducting research to identify additional features such as GDP, income of employees, population of the cities, etc to improve the prediction of the city development index. 

We created a train dataset based on the target variable "city_development_index" to see which variable would impact "city_development_index" the most. We included the following four features (most important featurs from our classification models) in our new train and test data : "experience", "enrolled_university_enrollment", "last_new_job", and "major_disciplineStem''. By picking linear regression as our best model, we can easily see that "experience", "enrolled_university_enrollment", and "last_new_job" have positive relationships with the "city_development_index". And as "enrolled_university_enrollment" increases, the target variable "city_development_index" increases more compared with the other two variables which all have a positive relationship with "city_development_index". 

*** 

### Recommendations

Candidates who are more likely to accept the job offer include those who:

- Reside in low developed cities 
- Do not have too much work experience
- Do not have any degree from universities (candidates with no formal undergraduate or graduate degrees might be more willing to receive work experience)

*** 

### Challenges Faced

- Low sensitivity rate: Not the best at predicting candidates who are going to be accepting job offers
- Imputation of values while cleaning data (examples include changing values with: greater than 20 years of experience as 21, less than 1 year of experience as 0)

*** 

### Future Work

- Regression variables used in the model might not be the only variables that are good predictors of the city development index. Unknown variables such as GDP, income and population levels might be better indicators
- Checking if dimensionality reduction techniques are required to account for highly correlated variables
